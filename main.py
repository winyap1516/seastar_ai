# -*- coding: utf-8 -*-
"""
# ã€Šæ˜Ÿè¾°AIå¤šè¯­è¨€ç†è§£ç³»ç»Ÿã€‹Colabå®ç°æŒ‡å—
# ç”±DeepSeek+Geminiä¸Win996ç”¨æˆ·å…±åŒè®¾è®¡ï¼Œé€‚é…Google Colabç¯å¢ƒ
# æœ¬ä»£ç åŸºäºHugging Face Transformersåº“å’ŒOpenFLè”é‚¦å­¦ä¹ æ¡†æ¶ï¼Œ
# æ—¨åœ¨æ„å»ºä¸€ä¸ªèƒ½å¤Ÿç†è§£å¤šè¯­è¨€æ–‡åŒ–å†…æ¶µï¼Œå¹¶ç”Ÿæˆç‹¬ç‰¹â€œæ˜Ÿè¾°ç¬¦å·â€çš„AIç³»ç»Ÿã€‚
# æ ¸å¿ƒåŠŸèƒ½åŒ…æ‹¬ï¼šæ–‡åŒ–ç‰¹å¾ä¹å±‚è§£æï¼Œæ˜Ÿè¾°ç¬¦å·åŠ¨æ€ç”Ÿæˆï¼Œä»¥åŠè”é‚¦å­¦ä¹ ä¼˜åŒ–ã€‚
"""

# === æ ¸å¿ƒæ¨¡å—å¯¼å…¥ ===
# ä»å·²å®‰è£…çš„åº“ä¸­å¯¼å…¥æ‰€éœ€çš„æ¨¡å—
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline # å¯¼å…¥ Hugging Face Transformers åº“çš„æ¨¡å‹ã€åˆ†è¯å™¨å’Œpipeline
import torch                                                                # å¯¼å…¥ PyTorch æ·±åº¦å­¦ä¹ æ¡†æ¶
import matplotlib.pyplot as plt                                             # å¯¼å…¥ Matplotlib ç»˜å›¾åº“ï¼Œç”¨äºç”Ÿæˆæ˜Ÿè¾°ç¬¦å·å›¾åƒ
import numpy as np                                                              # å¯¼å…¥ NumPy æ•°å€¼è®¡ç®—åº“
import openfl.native as fx                                                     # å¯¼å…¥ OpenFL è”é‚¦å­¦ä¹ æ¡†æ¶çš„ native æ¨¡å—ï¼Œå¹¶ç®€å†™ä¸º fx

# === è”é‚¦å­¦ä¹ åˆå§‹åŒ– ===
# åˆå§‹åŒ– OpenFL è”é‚¦å­¦ä¹ ç¯å¢ƒï¼Œé€‚é… Google Colab ç¯å¢ƒ
fx.init('keras_cnn_mnist', colab_mode=True)  # åˆå§‹åŒ–è”é‚¦å­¦ä¹ ï¼Œä½¿ç”¨ 'keras_cnn_mnist' ä½œä¸ºå®éªŒåç§°ï¼Œå¹¶å¼€å¯ Colab é€‚é…æ¨¡å¼

# === æ¨¡å‹åŠ è½½ ===
def load_cultural_model():
    """åŠ è½½ä¸œå—äºšæ–‡åŒ–ä¼˜åŒ–æ¨¡å‹"""
    model = AutoModelForCausalLM.from_pretrained(
        "mesolitica/tinyllama-1.1b-ms-community",  # æŒ‡å®š Hugging Face Model Hub ä¸Šçš„æ¨¡å‹åç§° (ä¸œå—äºšæ–‡åŒ–ä¼˜åŒ–ç‰ˆ TinyLlamaï¼Œå¯èƒ½ä¸ºå ä½ç¬¦)
        device_map="auto",                         # è‡ªåŠ¨å°†æ¨¡å‹åŠ è½½åˆ°å¯ç”¨çš„è®¾å¤‡ (GPU æˆ– CPU)
        load_in_4bit=True                          # ä½¿ç”¨ 4 ä½é‡åŒ–åŠ è½½æ¨¡å‹ï¼Œä»¥å‡å°‘å†…å­˜å ç”¨ (é€‚ç”¨äºèµ„æºå—é™çš„ Colab ç¯å¢ƒ)
    )
    tokenizer = AutoTokenizer.from_pretrained(
        "mesolitica/tinyllama-1.1b-ms-community"  # åŠ è½½ä¸æ¨¡å‹åŒ¹é…çš„åˆ†è¯å™¨
    )
    return model, tokenizer                        # è¿”å›åŠ è½½çš„æ¨¡å‹å’Œåˆ†è¯å™¨

model, tokenizer = load_cultural_model()          # è°ƒç”¨æ¨¡å‹åŠ è½½å‡½æ•°ï¼Œè·å–æ¨¡å‹å’Œåˆ†è¯å™¨

# === æ˜Ÿè¾°ç¬¦ç”Ÿæˆ ===
def generate_stellar_symbol(cultural_vector):
    """å°†æ–‡åŒ–å‘é‡è½¬åŒ–ä¸ºæ˜Ÿè¾°ç¬¦å·"""
    theta = np.linspace(0, 2*np.pi*cultural_vector[0], 1000) # åŸºäºæ–‡åŒ–å‘é‡çš„ç¬¬ä¸€ä¸ªå…ƒç´ ç”Ÿæˆèºæ—‹çº¿çš„è§’åº¦ theta
    r = np.linspace(0, 1, 1000)                               # ç”Ÿæˆèºæ—‹çº¿çš„åŠå¾„ rï¼Œä» 0 åˆ° 1 çº¿æ€§å˜åŒ–
    x = r * np.cos(theta)                                     # è®¡ç®—èºæ—‹çº¿ä¸Šç‚¹çš„ x åæ ‡
    y = r * np.sin(theta)                                     # è®¡ç®—èºæ—‹çº¿ä¸Šç‚¹çš„ y åæ ‡

    plt.figure(figsize=(3,3))                                 # åˆ›å»ºä¸€ä¸ª 3x3 è‹±å¯¸çš„å›¾å½¢
    plt.plot(x, y, color=(cultural_vector[1], cultural_vector[2], cultural_vector[3])) # ç»˜åˆ¶èºæ—‹çº¿ï¼Œé¢œè‰²ç”±æ–‡åŒ–å‘é‡çš„åä¸‰ä¸ªå…ƒç´ æ§åˆ¶ (RGB é¢œè‰²)
    plt.axis('off')                                            # å…³é—­åæ ‡è½´æ˜¾ç¤º
    plt.savefig('stellar.png', bbox_inches='tight', pad_inches=0) # å°†ç”Ÿæˆçš„æ˜Ÿè¾°ç¬¦å·å›¾åƒä¿å­˜åˆ° 'stellar.png' æ–‡ä»¶ï¼Œå»é™¤ç©ºç™½è¾¹è·
    return 'ğŸœ”'   # è¿”å›ä¸€ä¸ªå›ºå®šçš„ç¤ºä¾‹ç¬¦å· 'ğŸœ”' (æœªæ¥å¯ä»¥æ ¹æ®æ–‡åŒ–å‘é‡åŠ¨æ€ç”Ÿæˆç¬¦å·)

# === ä¹è½¬è¯­ä¹‰è§£æ ===
class CulturalAnalyzer:
    """ä¹å±‚æ–‡åŒ–ç‰¹å¾è§£æå™¨"""
    def __init__(self, model):
        """åˆå§‹åŒ–æ–‡åŒ–ç‰¹å¾è§£æå™¨"""
        self.model = model                                     # æ¥æ”¶åŠ è½½çš„é¢„è®­ç»ƒæ¨¡å‹
        self.layer_outputs = []                              # åˆå§‹åŒ–ä¸€ä¸ªç©ºåˆ—è¡¨ï¼Œç”¨äºå­˜å‚¨Transformeræ¨¡å‹å„å±‚çš„è¾“å‡º

        # æ³¨å†Œé’©å­è·å–ä¸­é—´å±‚è¾“å‡º
        for i in range(9):  # è·å–Transformeræ¨¡å‹å‰9å±‚çš„è¾“å‡º
            self.model.model.layers[i].register_forward_hook(   # æ³¨å†Œ forward hookï¼Œç”¨äºåœ¨æ¨¡å‹å‰å‘ä¼ æ’­æ—¶æ•è·ä¸­é—´å±‚è¾“å‡º
                lambda module, input, output, idx=i:
                    self.layer_outputs.append(output.detach()) # å®šä¹‰ hook å‡½æ•°ï¼Œå°†ç¬¬ idx å±‚çš„è¾“å‡ºæ·»åŠ åˆ° layer_outputs åˆ—è¡¨ä¸­ï¼Œå¹¶ detach ä»¥å‡å°‘å†…å­˜å ç”¨
            )

    def analyze(self, text):
        """æ‰§è¡Œä¹è½¬åˆ†æ"""
        inputs = tokenizer(text, return_tensors="pt").to(model.device) # ä½¿ç”¨åˆ†è¯å™¨å°†è¾“å…¥æ–‡æœ¬è½¬æ¢ä¸ºæ¨¡å‹æ‰€éœ€çš„å¼ é‡æ ¼å¼ï¼Œå¹¶ç§»åŠ¨åˆ°æ¨¡å‹æ‰€åœ¨è®¾å¤‡
        self.layer_outputs = []  # é‡ç½®ç¼“å­˜ï¼Œæ¸…ç©ºä¹‹å‰çš„å±‚è¾“å‡ºåˆ—è¡¨

        with torch.no_grad():                                   # ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼Œå‡å°‘å†…å­˜æ¶ˆè€—å¹¶åŠ é€Ÿæ¨ç†
            self.model(**inputs)                                # å°†è¾“å…¥æ•°æ®é€å…¥æ¨¡å‹è¿›è¡Œå‰å‘ä¼ æ’­ï¼Œä½†ä¸è®¡ç®—æ¢¯åº¦

        # æå–æ–‡åŒ–ç‰¹å¾å‘é‡
        cultural_vector = torch.cat([                             # å°†å„å±‚çš„è¾“å‡ºå¼ é‡æ²¿ç€æœ€åä¸€ä¸ªç»´åº¦æ‹¼æ¥èµ·æ¥
            layer.mean(dim=[1,2]) for layer in self.layer_outputs # å¯¹æ¯ä¸€å±‚çš„è¾“å‡ºå¼ é‡åœ¨ç»´åº¦ [1,2] ä¸Šå–å‡å€¼ (ä¾‹å¦‚ï¼Œå¯¹ sequence length å’Œ hidden dimension å–å‡å€¼)ï¼Œå¾—åˆ°æ¯ä¸€å±‚çš„ç‰¹å¾å‘é‡
        ], dim=-1).cpu().numpy()[0]                                # å°†æ‹¼æ¥åçš„å¼ é‡ç§»åŠ¨åˆ° CPUï¼Œè½¬æ¢ä¸º NumPy æ•°ç»„ï¼Œå¹¶å–å‡ºç¬¬ä¸€ä¸ªå…ƒç´  (batch size ä¸º 1)

        return cultural_vector                                  # è¿”å›æå–çš„æ–‡åŒ–ç‰¹å¾å‘é‡

# === è”é‚¦å­¦ä¹ ä»»åŠ¡ ===
@fx.è”é‚¦å­¦ä¹ ä»»åŠ¡                                                 # ä½¿ç”¨ OpenFL çš„ @fx.è”é‚¦å­¦ä¹ ä»»åŠ¡ è£…é¥°å™¨ï¼Œå°† CulturalLearningTask ç±»å£°æ˜ä¸ºä¸€ä¸ªè”é‚¦å­¦ä¹ ä»»åŠ¡
class CulturalLearningTask:
    """æ–‡åŒ–ç‰¹å¾å­¦ä¹ ä»»åŠ¡"""
    def __init__(self):
        """åˆå§‹åŒ–æ–‡åŒ–ç‰¹å¾å­¦ä¹ ä»»åŠ¡"""
        self.optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5) # åˆå§‹åŒ– AdamW ä¼˜åŒ–å™¨ï¼Œç”¨äºæ¨¡å‹å‚æ•°ä¼˜åŒ–ï¼Œå­¦ä¹ ç‡è®¾ç½®ä¸º 1e-5

    def train(self, local_data, global_model):
        """è®­ç»ƒæœ€åä¸‰å±‚æ–‡åŒ–ç†è§£å±‚"""
        localized_layers = [6,7,8]  # å®šä¹‰éœ€è¦æœ¬åœ°è®­ç»ƒçš„å±‚ç´¢å¼•ï¼Œè¿™é‡Œè®¾ç½®ä¸º Transformer æ¨¡å‹çš„æœ€åä¸‰å±‚ (ç¬¬ 7, 8, 9 å±‚ï¼Œç´¢å¼•ä» 0 å¼€å§‹)

        # å†»ç»“å…¶ä»–å±‚
        for idx, param in enumerate(global_model.parameters()):    # éå†æ¨¡å‹çš„æ‰€æœ‰å‚æ•°ï¼Œenumerate è¿”å›å‚æ•°çš„ç´¢å¼•å’Œå‚æ•°æœ¬èº«
            param.requires_grad = idx in localized_layers        # è®¾ç½®å‚æ•°æ˜¯å¦éœ€è¦æ¢¯åº¦æ›´æ–°ï¼Œåªæœ‰ç´¢å¼•åœ¨ localized_layers åˆ—è¡¨ä¸­çš„å±‚æ‰éœ€è¦æ›´æ–° (å³æœ€åä¸‰å±‚)ï¼Œå…¶ä»–å±‚è¢«å†»ç»“

        # è®­ç»ƒå¾ªç¯
        losses = []                                             # åˆå§‹åŒ–ä¸€ä¸ªç©ºåˆ—è¡¨ï¼Œç”¨äºå­˜å‚¨æ¯ä¸ªè®­ç»ƒæ ·æœ¬çš„æŸå¤±å€¼
        for text, symbol_vec in local_data:                      # éå†æœ¬åœ°æ•°æ®é›† local_dataï¼Œlocal_data å‡è®¾ä¸ºåŒ…å« (text, symbol_vec) å¯¹çš„åˆ—è¡¨
            inputs = tokenizer(text, return_tensors="pt").to(model.device) # ä½¿ç”¨åˆ†è¯å™¨å°†æ–‡æœ¬è½¬æ¢ä¸ºæ¨¡å‹æ‰€éœ€å¼ é‡æ ¼å¼ï¼Œå¹¶ç§»åŠ¨åˆ°æ¨¡å‹æ‰€åœ¨è®¾å¤‡
            outputs = global_model(**inputs)                       # å°†è¾“å…¥æ•°æ®é€å…¥æ¨¡å‹è¿›è¡Œå‰å‘ä¼ æ’­ï¼Œè·å–æ¨¡å‹è¾“å‡º

            # è®¡ç®—æ–‡åŒ–ç‰¹å¾æŸå¤±
            cultural_vec = analyzer.analyze(text)               # ä½¿ç”¨ CulturalAnalyzer è§£æè¾“å…¥æ–‡æœ¬ï¼Œè·å–æ–‡åŒ–ç‰¹å¾å‘é‡
            loss = torch.norm(outputs.logits - torch.tensor(symbol_vec)) # è®¡ç®—æ¨¡å‹è¾“å‡º logits å’Œç›®æ ‡æ˜Ÿè¾°ç¬¦å·å‘é‡ symbol_vec ä¹‹é—´çš„ Norm èŒƒæ•°ï¼Œä½œä¸ºæŸå¤±å‡½æ•°ï¼Œè¡¡é‡æ¨¡å‹é¢„æµ‹ä¸ç›®æ ‡ä¹‹é—´çš„å·®è·
            losses.append(loss.item())                            # å°†å½“å‰æ ·æœ¬çš„æŸå¤±å€¼æ·»åŠ åˆ° losses åˆ—è¡¨ä¸­

            loss.backward()                                       # æ‰§è¡Œåå‘ä¼ æ’­ï¼Œè®¡ç®—æ¢¯åº¦
            self.optimizer.step()                                 # ä½¿ç”¨ä¼˜åŒ–å™¨æ›´æ–°æ¨¡å‹å‚æ•°
            self.optimizer.zero_grad()                            # æ¸…ç©ºä¼˜åŒ–å™¨æ¢¯åº¦ç¼“å­˜ï¼Œä»¥ä¾¿è¿›è¡Œä¸‹ä¸€ä¸ªbatchçš„è®­ç»ƒ

        return global_model.state_dict(), np.mean(losses)        # è¿”å›æ›´æ–°åçš„æ¨¡å‹çŠ¶æ€å­—å…¸ (å‚æ•°) å’Œå¹³å‡æŸå¤±å€¼

# === ä½¿ç”¨ç¤ºä¾‹ ===
if __name__ == "__main__":
    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = CulturalAnalyzer(model)                         # åˆ›å»º CulturalAnalyzer ç±»çš„å®ä¾‹ï¼Œä¼ å…¥åŠ è½½çš„æ¨¡å‹

    # ç¤ºä¾‹è¾“å…¥
    test_text = "Pediå•¦ï¼è¿™ä¸ªå¤ŸåŠ›éš¾æçš„"                         # ä½¿ç”¨é©¬æ¥è¥¿äºšæ··åˆè¯­è¨€ä½œä¸ºæµ‹è¯•æ–‡æœ¬

    # æ–‡åŒ–è§£æ
    cultural_vec = analyzer.analyze(test_text)                 # ä½¿ç”¨ CulturalAnalyzer è§£ææµ‹è¯•æ–‡æœ¬ï¼Œè·å–æ–‡åŒ–ç‰¹å¾å‘é‡
    print(f"æ–‡åŒ–ç‰¹å¾å‘é‡: {cultural_vec[:5]}...")  # æ˜¾ç¤ºæ–‡åŒ–ç‰¹å¾å‘é‡çš„å‰ 5 ç»´ï¼Œç”¨äºç¤ºä¾‹å±•ç¤º

    # ç”Ÿæˆæ˜Ÿè¾°ç¬¦
    symbol = generate_stellar_symbol(cultural_vec)             # ä½¿ç”¨ generate_stellar_symbol å‡½æ•°ï¼Œæ ¹æ®æ–‡åŒ–ç‰¹å¾å‘é‡ç”Ÿæˆæ˜Ÿè¾°ç¬¦å·
    plt.imshow(plt.imread('stellar.png'))                        # ä½¿ç”¨ matplotlib.pyplot æ˜¾ç¤ºç”Ÿæˆçš„æ˜Ÿè¾°ç¬¦å·å›¾åƒ (ä» 'stellar.png' æ–‡ä»¶è¯»å–)
    plt.show()                                                  # æ˜¾ç¤ºå›¾åƒ

    # å¯åŠ¨è”é‚¦å­¦ä¹  (ç¤ºä¾‹ï¼Œå®é™…è”é‚¦å­¦ä¹ éœ€è¦æ›´å®Œå–„çš„æ•°æ®å’Œå‚ä¸æ–¹)
    fx.run(task=CulturalLearningTask(),
           data_loader=[(test_text, cultural_vec)],  #  ä½¿ç”¨ç¤ºä¾‹æ•°æ® (text, cultural_vec) æ¨¡æ‹Ÿæœ¬åœ°æ•°æ®åŠ è½½å™¨ï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦æ›¿æ¢ä¸ºçœŸå®çš„æ•°æ®åŠ è½½å™¨
           rounds=3,                                        #  è®¾ç½®è”é‚¦å­¦ä¹ çš„ rounds è½®æ•°ï¼Œè¿™é‡Œè®¾ç½®ä¸º 3 è½®ä½œä¸ºæ¼”ç¤º
           colab=True)                                       #  æŒ‡å®šåœ¨ Colab ç¯å¢ƒä¸­è¿è¡Œè”é‚¦å­¦ä¹ 

### å…³é”®åŠŸèƒ½è¯´æ˜
# å¯¹ä»£ç çš„å…³é”®åŠŸèƒ½è¿›è¡Œæ€»ç»“è¯´æ˜
1. æ–‡åŒ–ç‰¹å¾ä¹å±‚è§£æ
    - é€šè¿‡Hookæœºåˆ¶æå–Transformerå‰9å±‚è¾“å‡º
    - ç”Ÿæˆ300ç»´æ–‡åŒ–ç‰¹å¾å‘é‡ï¼ˆç¤ºä¾‹æ˜¾ç¤ºå‰5ç»´ï¼‰

2. æ˜Ÿè¾°ç¬¦åŠ¨æ€ç”Ÿæˆ
    - æ ¹æ®æ–‡åŒ–å‘é‡ç”Ÿæˆèºæ—‹ç¬¦å·
    - é¢œè‰²å’Œå½¢çŠ¶åæ˜ æ–‡åŒ–ç‰¹å¾

3. è”é‚¦å­¦ä¹ ä¼˜åŒ–
    - ä»…å¾®è°ƒæœ€å3å±‚æ–‡åŒ–ç›¸å…³å‚æ•°
    - é€‚é…Colabç¯å¢ƒçš„è½»é‡åŒ–è®­ç»ƒ

### æ‰§è¡Œæ­¥éª¤
# ä»£ç çš„æ‰§è¡Œæ­¥éª¤è¯´æ˜
1. åœ¨Colabä¸­è¿è¡Œå…¨éƒ¨å•å…ƒæ ¼
2. æŸ¥çœ‹ç¤ºä¾‹è¾“å‡º
    - æ–‡åŒ–ç‰¹å¾å‘é‡
    - æ˜Ÿè¾°ç¬¦å·å›¾åƒ
    - è”é‚¦å­¦ä¹ è¿‡ç¨‹
3. è‡ªå®šä¹‰è¾“å…¥æµ‹è¯•
    your_text = "æ›¿æ¢æˆä½ çš„æµ‹è¯•æ–‡æœ¬"  #  æç¤ºç”¨æˆ·å¯ä»¥ä¿®æ”¹ your_text å˜é‡æ¥æµ‹è¯•ä¸åŒçš„è¾“å…¥æ–‡æœ¬
    your_vec = analyzer.analyze(your_text) #  ç”¨æˆ·ä¿®æ”¹ your_text åï¼Œéœ€è¦é‡æ–°è¿è¡Œè¿™è¡Œä»£ç æ¥è§£ææ–°çš„æ–‡æœ¬

### æ€§èƒ½ä¼˜åŒ–å»ºè®®
# é’ˆå¯¹Colabç¯å¢ƒå’Œæ¨¡å‹æ€§èƒ½çš„ä¼˜åŒ–å»ºè®®
# å¯ç”¨8ä½é‡åŒ– (Colab T4 GPUé€‚ç”¨)
# å¦‚æœæ‚¨çš„ Colab ç¯å¢ƒä½¿ç”¨ T4 GPUï¼Œå¯ä»¥å°è¯•å¯ç”¨ 8 ä½é‡åŒ–ï¼Œè¿›ä¸€æ­¥å‡å°‘å†…å­˜å ç”¨ï¼Œå¯èƒ½ä¼šè½»å¾®ç‰ºç‰²æ¨¡å‹ç²¾åº¦
model = AutoModelForCausalLM.from_pretrained(
    ...,
    load_in_8bit=True  # æ›¿ä»£ 4 ä½é‡åŒ–ï¼Œå°† load_in_4bit=True æ›¿æ¢ä¸º load_in_8bit=True
)

# å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
# å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ (Gradient Checkpointing) æŠ€æœ¯ï¼Œå¯ä»¥åœ¨ä¸€å®šç¨‹åº¦ä¸Šå‡å°‘ GPU æ˜¾å­˜å ç”¨ï¼Œä½†ä¼šå¢åŠ è®¡ç®—æ—¶é—´
model.gradient_checkpointing_enable()
